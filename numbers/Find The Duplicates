Given two sorted arrays arr1 and arr2 of passport numbers, implement a function findDuplicates that returns an array 
of all passport numbers that are both in arr1 and arr2. Note that the output array should be sorted in an ascending order.

Let N and M be the lengths of arr1 and arr2, respectively. Solve for two cases and analyze the time & space 
complexities of your solutions: M ≈ N - the array lengths are approximately the same M ≫ N - arr2 is much bigger than arr1.

Example:

input:  arr1 = [1, 2, 3, 5, 6, 7], arr2 = [3, 6, 7, 8, 20]

output: [3, 6, 7] # since only these three values are both in arr1 and arr2
Constraints:

[time limit] 5000ms

[input] array.integer arr1

1 ≤ arr1.length ≤ 100
[input] array.integer arr2

1 ≤ arr2.length ≤ 100
[output] array.integer

Solution for each case:
case 1 when M ~ N

vector<int> findDuplicates(vector <int> arr1, vector <int> arr2){
  int n = arr1.size();
  int m = arr2.size();
  int i , j = 0;
  while(i < arr1.size() && j < arr2.size()){
    if(arr1[i] == arr2[j]){
      result.push_back(arr1[i]);
      i++;
      j++;
    }
    else if(arr1[i] > arr2[j]){
      j++;
    }
    else 
      i++;
  }
  if(result.size() == 0)
    return -1;
  return result;
}

This solution has linear time complexity with O(n) is n is larger and O(m) if m is larger.
Time Complexity: O(N+M) since in the worst case scenario we traverse both arrays once. Note that O(N+M) is a linear time complexity because the input size is O(N+M) as well.

Space Complexity: the variable duplicates is the only dynamic auxiliary space we’re using in the algorithm. In 
the worst case scenario, the size of duplicates is going to be as big as big as the smaller input array. For 
instance, when the smaller array is fully contained within the bigger one. The space complexity is therefore O(N), 
where N ≤ M.

Case 2: if M > N = the time complexity is O(nlogm) in this case and space compledxity will be O(n) worst case.

vector<int> findDuplicates(vector<int> &arr1, vector<int> &arr2) {
  // your code goes here
  int n = arr1.size();
  int m = arr2.size();
  int start = 0;
  int end = m-1;
  vector<int> result;
  for(int i = 0; i < arr1.size(); i++){
    while(start < end){
      int mid = start + (end-start)/2;
      if(arr1[i] == arr2[mid]){
        result.push_back(arr1[i]);
      }
      else if(arr1[i] > arr2[mid])
        start = mid+1;
      else 
        end = mid-1;
    }
    start = 0;
    end = m-1;
  }
  return result;
}
// 3, 6, 7

int main() {
  vector <int> arr1 = {1,2,3,5,6,7};
  vector <int> arr2 = {3,6,7,8,20};
  vector <int> result = findDuplicates(arr1,arr2);
  for(int i = 0; i < result.size(); i++)
    cout << result[i];
  return 0;
}

Time Complexity: we running a binary search on arr2 N times. Hence the time complexity is O(N⋅log(M)).
So why is this algorithm better than the previous one when M ≫ N? To demonstrate that let’s analyze the
case that M = N^C, where C is a constant such that C 2. In this case, the time complexity of the second 
algorithm is: O(N⋅log(M)) = O(N⋅log(N^C)) = O(C⋅N⋅log(N)) = O(N⋅log(N)) And the time complexity of the
first algorithm is: O(N + M) = O(N + N^C) = O(N^C) As we all know O(N^C) > O(N⋅log(N)).

Space Complexity: the variable duplicates is the only dynamic auxiliary space we’re using in the algorithm.
In the worst case scenario, the size of duplicates is going to be as big as big as the smaller input array.
For instance, when the smaller array is fully contained within the bigger one. The space complexity is therefore O(N),
where N ≤ M.
