/*
 * Our team wants to create a new system to graph time series data
 * of events occurring on Twitter so we can visually monitor health
 * and throughput of Twitter systems. Our task is to create a library
 * that will be called by other systems for both recording these
 * events and also to query these events. Events generated by these
 * other systems will be done in real-time, consisting of an event
 * name and a Unix timestamp in milliseconds.
 *
 * Example events:
 * 
 * "like",    1603741739000  // 12:48:59
 * "like",    1603741766000  // 12:49:26
 * "like",    1603741738000  // 12:48:58
 * "retweet", 1603568988000  // 12:49:48
 * "sent",    1603395048000  // 12:30:48
 * "delete",  1571772648000  // 12:30:48
 * 
 * Additionally, our library needs to expose a way to query the counts
 * of these events, e.g. to be displayed in a visual distribution
 * graph, given a granularity (counts by minute, hour or day), the
 * event name, and start and and end time as Unix timestamps.
 * 
 * Example Query:
 * 
 *   - eventName = "com.twitter.tweet.like"
 *   - granularity = MINUTE
 *   - start = 1603741680000 // 12:48:00
 *   - end = 1603741860000   // 12:51:00
 * 
 *  ___
 * | 2 |  ___ 
 * |   | | 1 |  ___
 * =================
 * 12:48 12:49 12:50
 * 
 * Example return value:
 *
 * {
 *   "com.twitter.tweet.like": {
 *     "1603741680000": 2,
 *     "1603741740000": 1,
 *     "1603741800000": 0
 *   }
 * }
 key: event name (string)
 value: unix timestamp (uint64_t)
unordered_map<string, vector<uint64_t>> event_time; 
unordered_map<uint64_t, long long int> event_aggregator; //1603741680000": 2

write : 
key -> value
like -> {1603741739000,1603741766000, 1603741738000}
retweet -> {1603568988000}
sent -> {1603395048000}
delete -> {}
 
 object = {string, vector pair<uint64_t, int>}
 
 {no_event, {0,0} }
 
 aggregator api :
 aggregator(eventName, granularity, start_time, end_time) {
     if(does event_time contains eventName) {
         
     }
     else {
         event is not present
     }
 }
 *
 
  *   - eventName = "com.twitter.tweet.like"
 *   - granularity = MINUTE
 *   - start = 1603741680000 // 12:48:00
 *   - end = 1603741860000   // 12:53:00
 
 
 *
 * {
 *   "com.twitter.tweet.like": {
 *     "1603741680000": 2,
 *     "1603741740000": 1,
 *     "1603741800000": 0,
        "1603741860000" :0,
        ""
 *   }
 * }
 
 */



#include <iostream>
#include <cmath>
#include <cstdio>
#include <string>
#include <vector>
#include <algorithm>
#include <unordered_map>
#include <unordered_set>
#include <chrono>
#include <unistd.h>

/*

 key: event name (string)
 value: unix timestamp (uint64_t)
unordered_map<string, vector<uint64_t>> event_time; 
unordered_map<uint64_t, long long int> event_aggregator; //1603741680000": 2
write : 
key -> value
like -> {1603741739000,1603741766000, 1603741738000}
retweet -> {1603568988000}
sent -> {1603395048000}
delete -> {}
 
 object = {string, vector pair<uint64_t, int>}
 
 {no_event, {0,0} }
 
 aggregator api :
 aggregator(eventName, granularity, start_time, end_time) {
     if(does event_time contains eventName) {
         
     }
     else {
         event is not present
     }
 }
*/

using namespace std;


class event_read_write {

    private:
    unordered_set<string> valid_events;
    unordered_map<string, vector<uint64_t>> event_time;
    unordered_map<uint64_t, long long int> event_aggregator;
    unordered_map<string, unordered_map<uint64_t,long long int>> MINUTE; //unordered_map<key = string(event_name), value = unordered_map<uint64_t,long long int>> (timestamp, count)> MINUTE;
    unordered_map<string, unordered_map<uint64_t,long long int>> HOUR; //preprocessing hourly granularity to reduce time taken for aggregation method
    unordered_map<string, unordered_map<uint64_t,long long int>> DAY;//preprocessing daily granularity to reduce time taken for aggregation method
    unordered_map<string, unordered_map<uint64_t,long long int>> result;
    public:
    void create_event_timestamp(string event, uint64_t timestamp) {
        if(event_time.find(event) == event_time.end()) {
            vector<uint64_t> temp = {timestamp};
            event_time.insert(make_pair(event,temp));
            valid_events.insert(event); //<-- setting valid events here
        }
        else {
            event_time[event].push_back(timestamp);
        }
    }
    
    
    //preprocessing step events by minute, hour and day granularity and store it as a hashmap of with names MINUTE, HOUR, DAY. Setup a cron job that runs even minute to update the MINUTE hashmap, cronjob runs every hour to update the HOUR hashmap (this can be built using the MINUTE hashmap) and every DAY to update the DAY hashmap(we can use the HOUR hashmap to build this).
    /*
        for example:
        MINUTE hashmap = unordered_map<key = string(event_name), value = unordered_map<uint64_t,long long int>> (timestamp, count)> MINUTE;
        create MINUTE_HASHMAP_ALL_EVENTS() {
                for(unordered_set<string>::iterator it = valid_events.begin(); it != valid_events.end(); ++it) {
                //create a MINUTE HASHMAP where key = event_name, value = pair(uint64_t,long long int). use the event_time hashmap for this
                    unordered_map<string, unordered_map<uint64_t,long long int>> MINUTE;
                    vector<uint64_t> timestamps = event_time[*it];
                    unordered_map<uint64_t,long long int> time_count;
                    vector<long long int> count(timestamps.size(), 0);
                    for(uint64_t t = 0; t < timestamps.size(); t++) {
                        count[t-t%60]++;
                        time_count.insert(make_pair(t-t%60, count[t]));
                    }
                }
                MINUTE.insert(make_pair(*it, time_count));
            }            
        }
        HOUR hashmap = unordered_map<key = string(event_name), value = <uint64_t,long long int> (timestamp, count)> DAY;
        DAY hashmap = unordered_map<key = string(event_name), value = <uint64_t,long long int> (timestamp, count)> HOUR; 
    */
    
    void MINUTE_HASHMAP_ALL_EVENTS() {
        for(unordered_set<string>::iterator it = valid_events.begin(); it != valid_events.end(); ++it) {
            string event_name = *it;
        //create a MINUTE HASHMAP where key = event_name, value = pair(uint64_t,long long int). use the event_time hashmap for this
            vector<uint64_t> timestamps = event_time[event_name];
            unordered_map<uint64_t,long long int> time_count;
            vector<long long int> count(timestamps.size(), 0);
            for(uint64_t t = 0; t < timestamps.size(); t++) {
                count[t-t%60000]++;
                time_count.insert(make_pair(t-t%60000, count[t]));
            }
            MINUTE.insert(make_pair(event_name,time_count));
        }
    }            
    
    void HOUR_HASHMAP_ALL_EVENTS() {
        for(unordered_set<string>::iterator it = valid_events.begin(); it != valid_events.end(); ++it) {
            string event_name = *it;
        //create a MINUTE HASHMAP where key = event_name, value = pair(uint64_t,long long int). use the event_time hashmap for this
            vector<uint64_t> timestamps = event_time[event_name];
            unordered_map<uint64_t,long long int> time_count;
            vector<long long int> count(timestamps.size(), 0);
            for(uint64_t t = 0; t < timestamps.size(); t++) {
                count[t-((t%60000)*60)]++;
                time_count.insert(make_pair(t-((t%60000)*60), count[t]));
            }
            HOUR.insert(make_pair(event_name,time_count));
        }
    }
    
    void DAY_HASHMAP_ALL_EVENTS() {
        for(unordered_set<string>::iterator it = valid_events.begin(); it != valid_events.end(); ++it) {
            string event_name = *it;
        //create a MINUTE HASHMAP where key = event_name, value = pair(uint64_t,long long int). use the event_time hashmap for this
            vector<uint64_t> timestamps = event_time[event_name];
            unordered_map<uint64_t,long long int> time_count;
            vector<long long int> count(timestamps.size(), 0);
            for(uint64_t t = 0; t < timestamps.size(); t++) {
                count[t-(((t%60000)*60)*24)]++;
                time_count.insert(make_pair(t-(((t%60000)*60)*24), count[t]));
            }
            DAY.insert(make_pair(event_name,time_count));
        }
    }
    
    unordered_map<string, unordered_map<uint64_t,long long int>> aggregation(string event_name, int granular, uint64_t start_time, uint64_t end_time) {
        //if(Event is invalid, throw exception )
        //first step validate start_time and end_time. start_time cannot be more than end_time. end_time cannot be more than current time. if either of these conditions fail, throw an exception about incorrect times as input.
        enum granularity{minute,hour,day};
        granularity g;
        unordered_map<uint64_t,long long int> temp;
        if(start_time == end_time) {
            temp[start_time] = 0;
            result.insert(make_pair(event_name,temp));
            return result;
        }
        if(event_time.find(event_name) != event_time.end()) {
            int index = 0;
            if(g+granular == 0) {
                //find the closest minute and set the start time to that value;

                unordered_map<uint64_t,long long int> curr_map = MINUTE[event_name];
                while(start_time <= end_time) {
                    index++;
                    if(curr_map.find(start_time-start_time%60000) != curr_map.end()) {
                        temp[start_time] = curr_map[start_time];
                    }
                    start_time += 60000;
                }
            }
            else if (g+granular == 1) {
                unordered_map<uint64_t,long long int> curr_map = HOUR[event_name];
                //find the closest hour and set the start time to that value;

                while(start_time <= end_time) {
                    index++;
                    if(curr_map.find(start_time-start_time%60000*60) != curr_map.end()) {
                        temp[start_time] = curr_map[start_time];
                    }
                    start_time += 60000 * 60;
                }
            }
            else if (g+granular == 2) {
                unordered_map<uint64_t,long long int> curr_map = DAY[event_name];
                //find the closest day and set the start time to that value;
                while(start_time <= end_time) {
                    index++;
                    if(curr_map.find(start_time-start_time%60000*60) != curr_map.end()) {
                        temp[start_time] = curr_map[start_time];
                    }
                    start_time += 60000 * 60;
                }
            }
            else {
                throw "Granularity not accept";
            }
            result.insert(make_pair(event_name,temp));

        }
        else {
            throw "No such event"; 
        }
        return result;
    }
        //checked validity/exceptions for start_time and end_time.
        //checked validity/exception handling for valid event;
        //checked validity/exceptions for granuarity.
    
    
};

int main() {
    event_read_write e;
    e.create_event_timestamp("like", std::chrono::duration_cast<std::chrono::milliseconds>(std::chrono::system_clock::now().time_since_epoch()).count());
    usleep(500);
    e.create_event_timestamp("like", std::chrono::duration_cast<std::chrono::milliseconds>(std::chrono::system_clock::now().time_since_epoch()).count());
    e.create_event_timestamp("retweet", std::chrono::duration_cast<std::chrono::milliseconds>(std::chrono::system_clock::now().time_since_epoch()).count());
    e.create_event_timestamp("like", std::chrono::duration_cast<std::chrono::milliseconds>(std::chrono::system_clock::now().time_since_epoch()).count());
    usleep(500);
    e.create_event_timestamp("delete", std::chrono::duration_cast<std::chrono::milliseconds>(std::chrono::system_clock::now().time_since_epoch()).count());
    e.create_event_timestamp("delete", std::chrono::duration_cast<std::chrono::milliseconds>(std::chrono::system_clock::now().time_since_epoch()).count());
    e.create_event_timestamp("retweet", std::chrono::duration_cast<std::chrono::milliseconds>(std::chrono::system_clock::now().time_since_epoch()).count());
    usleep(500);
    e.create_event_timestamp("sent", std::chrono::duration_cast<std::chrono::milliseconds>(std::chrono::system_clock::now().time_since_epoch()).count());
    cout << "find the number of LIKE events in MINUTE granularity :" << e.aggregation("like", 0, 1603741680000, 1603742680000 )
    return 0;
}
